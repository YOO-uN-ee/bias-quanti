# Quantifying Bias in Language Models
What matters more? Model architecture? Model size? Training Data?
Tracking down the source/cause of bias that gets propagated through language models.

Models:
- BERT
- [RoBERTa](https://huggingface.co/FacebookAI/roberta-base)
- DistilBERT
- DeBERTa
- Electra
- XLNet
- ModernBERT
- AlBERT

Corpus:
- BookCorpus
- Wikipedia
- [CommonCrawl](https://github.com/allenai/allennlp/discussions/5056)
- [Gigawords](https://huggingface.co/datasets/Harvard/gigaword/discussions)
    - https://www.tensorflow.org/datasets/catalog/gigaword
- Clueweb
    - Cannot use due to access issue
- [OpenWebText](https://github.com/jcpeterson/openwebtext)
- Stories